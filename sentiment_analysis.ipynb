{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianneargsino/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import any necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacytextblob.spacytextblob.SpacyTextBlob at 0x120d1bb80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the spacy english model (medium) and add pipeline\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset into pandas dataframe\n",
    "amazon_df = pd.read_csv('amazon_product_reviews.csv', low_memory=False)\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I thought it would be as big as small paper bu...\n",
      "1    This kindle is light and easy to use especiall...\n",
      "2    Didnt know how much i'd use a kindle so went f...\n",
      "3    I am 100 happy with my purchase. I caught it o...\n",
      "4    Solid entry level Kindle. Great for kids. Gift...\n",
      "Name: reviews.text, dtype: object\n",
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display dataframe\n",
    "print(amazon_df[\"reviews.text\"].head())\n",
    "print(amazon_df[\"reviews.text\"].shape)\n",
    "amazon_df[\"reviews.text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "0    I thought it would be as big as small paper bu...\n",
      "1    This kindle is light and easy to use especiall...\n",
      "2    Didnt know how much i'd use a kindle so went f...\n",
      "3    I am 100 happy with my purchase. I caught it o...\n",
      "4    Solid entry level Kindle. Great for kids. Gift...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#drop any rows with missing values and prints\n",
    "clean_data = amazon_df[[\"reviews.text\", \"reviews.title\"]]\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and extract individual words\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    preprocessed_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            clean_token = token.lemma_.lower()\n",
    "            preprocessed_tokens.append(clean_token)\n",
    "    \n",
    "    return preprocessed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    think big small paper turn like palm think sma...\n",
      "1               kindle light easy use especially beach\n",
      "2    not know use kindle go low end m happy little ...\n",
      "3    100 happy purchase catch sale good price norma...\n",
      "4    solid entry level kindle great kid gifted kid ...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "clean_data['processed_reviews'] = clean_data['reviews.text'].apply(preprocess_text)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis function\n",
    "def sentiment_analysis(review):\n",
    "    polarity_value = review._.blob.polarity\n",
    "    subjectivity_value = review._.blob.subjectivity\n",
    "    \n",
    "    return polarity_value, subjectivity_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the spacy english model (medium)\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to compare the similarity between two reviews\n",
    "def similarity(first, second):\n",
    "    similarity_results = nlp(first).similarity(nlp(second))\n",
    "    return(similarity_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review one: This Echo Show comes in handy. I use it almost as much as I thought I would. I am still learning all that it can do, but my favorite part is the screen. It‚Äôs not a huge deal, but if I could change one thing it would be a detachable power cable instead of hardwired.\n",
      "Review two: Great item to upgrade your house. Works very well.\n",
      "Similarity: ('This Echo Show comes in handy. I use it almost as much as I thought I would. I am still learning all that it can do, but my favorite part is the screen. It‚Äôs not a huge deal, but if I could change one thing it would be a detachable power cable instead of hardwired.', 'Great item to upgrade your house. Works very well.')\n"
     ]
    }
   ],
   "source": [
    "first_review = clean_data['processed_reviews'][203]\n",
    "second_review = clean_data['processed_reviews'][659]\n",
    "print(f\"Review one: {first_review}\")\n",
    "print(f\"Review two: {second_review}\")\n",
    "print(f\"Similarity: {similarity(first_review, second_review)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = defaultdict(int)\n",
    "negative_words = defaultdict(int)\n",
    "\n",
    "# Process each review, extract individual words, and perform sentiment analysis\n",
    "for review_text in clean_data['reviews.text'].values:\n",
    "    tokens = preprocess_text(review_text)\n",
    "    review_doc = nlp(\" \".join(tokens))\n",
    "    polarity_value, _ = sentiment_analysis(review_doc)\n",
    "    \n",
    "    if polarity_value > 0:\n",
    "        for word in tokens:\n",
    "            positive_words[word] += 1\n",
    "    elif polarity_value < 0:\n",
    "        for word in tokens:\n",
    "            negative_words[word] += 1\n",
    "\n",
    "# Check the content of positive words and negative words\n",
    "print(\"Positive words:\", positive_words)\n",
    "print(\"Negative words:\", negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the content of positive_words and negative_words\n",
    "print(\"Positive words:\", positive_words)\n",
    "print(\"Negative words:\", negative_words)\n",
    "\n",
    "print(\"Positive words count:\", len(positive_words))\n",
    "print(\"Negative words count:\", len(negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds from positive and negative word frequencies\n",
    "pos_wordcloud = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(positive_words)\n",
    "neg_wordcloud = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(negative_words)\n",
    "\n",
    "# Display the word clouds\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "ax[0].imshow(pos_wordcloud, interpolation='bilinear')\n",
    "ax[0].set_title('Positive Words')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(neg_wordcloud, interpolation='bilinear')\n",
    "ax[1].set_title('Negative Words')\n",
    "ax[1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
